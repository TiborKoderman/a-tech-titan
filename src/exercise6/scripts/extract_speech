#!/usr/bin/python3

import roslib
import time
import rospy
import enum

import speech_recognition as sr

from exercise6.srv import Barrels, BarrelsResponse



class SpeechTranscriber:
    def __init__(self):
        rospy.init_node('speech_transcriber', anonymous=True)
        
        # The documentation is here: https://github.com/Uberi/speech_recognition

        # The main interface to the speech recognition engines
        self.sr = sr.Recognizer()
        
        # These are the methods that are available to us for recognition.
        # Please note that most of them use an internet connection and currently they are using
        # a default API user/pass, so there are restrictions on the number of requests we can make.
        # recognize_bing(): Microsoft Bing Speech
        # recognize_google(): Google Web Speech API
        # sr.recognize_google();
        # recognize_google_cloud(): Google Cloud Speech - requires installation of the google-cloud-speech package
        # recognize_houndify(): Houndify by SoundHound
        # recognize_ibm(): IBM Speech to Text
        # recognize_sphinx(): CMU Sphinx - requires installing PocketSphinx
        # recognize_wit(): Wit.ai
        
        # An interface to the default microphone
        self.mic = sr.Microphone()
        sr.Microphone.list_microphone_names()
        
        # You can get the list of available devices: sr.Microphone.list_microphone_names()
    # You can set the fault microphone like this: self. mic = sr.Microphone(device_index=3)
    # where the device_index is the position in the list from the first command.


    def recognize_speech(self):
        with self.mic as source:
            print('Adjusting mic for ambient noise...')
            self.sr.adjust_for_ambient_noise(source)
            print('SPEAK NOW!')
            audio = self.sr.listen(source)
        
        detectedColors = []
        print('I am now processing the sounds you made.')
        recognized_text = ''
        try:
            recognized_text = self.sr.recognize_google(audio)
            print('I recognized this sentence:', recognized_text)
            for word in recognized_text.split():
                if word in ['red', 'green', 'blue', 'yellow']:
                    detectedColors.append(word);
                if word == "no":
                    return ["no"]
            if len(detectedColors) == 0:
                print('I did not recognize any colors.')
            elif len(detectedColors) == 2:
                return detectedColors
                print('I recognized these cylinders:', detectedColors)
            else:
                print("please say two colors")
                return ""

        except sr.RequestError as e:
            print('API is probably unavailable', e)
        except sr.UnknownValueError:
            print('Did not manage to recognize anything.')
        
        return []
        

def handleExtractSpeech(req):
    cylinders = []
    while not rospy.is_shutdown() and (len(cylinders) != 2 or cylinders[0] != "no"):
        cylinders = st.recognize_speech()
        if(len(cylinders) == 2):
            print('I recognized these barrels:', cylinders)
        if cylinders[0] == "no":
            print("no information")
        time.sleep(5)
    return BarrelsResponse(cylinders)



if __name__ == '__main__':
    st = SpeechTranscriber()
    s = rospy.Service('extract_speech', Barrels, handleExtractSpeech)
    rospy.spin()




